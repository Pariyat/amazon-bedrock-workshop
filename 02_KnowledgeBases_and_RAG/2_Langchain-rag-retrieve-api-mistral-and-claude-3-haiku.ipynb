{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Q&A application using Knowledge Bases for Amazon Bedrock - Retrieve API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context\n",
    "\n",
    "In this notebook, we will dive deep into building Q&A application using Knowledge Bases for Amazon Bedrock - Retrieve API. Here, we will query the knowledge base to get the desired number of document chunks based on similarity search. We will then augment the prompt with relevant documents and query which will go as input to Anthropic Claude V2 for generating response.\n",
    "\n",
    "With a knowledge base, you can securely connect foundation models (FMs) in Amazon Bedrock to your company\n",
    "data for Retrieval Augmented Generation (RAG). Access to additional data helps the model generate more relevant,\n",
    "context-speciﬁc, and accurate responses without continuously retraining the FM. All information retrieved from\n",
    "knowledge bases comes with source attribution to improve transparency and minimize hallucinations. For more information on creating a knowledge base using console, please refer to this [post](https://docs.aws.amazon.com/bedrock/latest/userguide/knowledge-base.html).\n",
    "We will cover 2 parts in the notebook:\n",
    "- Part 1, we will share how you can use `RetrieveAPI` with foundation models from Amazon Bedrock. We will use the `mistral.mistral-7b` model. \n",
    "- Part 2, we will showcase the langchain integration using Anthropic Claude 3 Haiku model.\n",
    "\n",
    "### Pattern\n",
    "\n",
    "We can implement the solution using Retreival Augmented Generation (RAG) pattern. RAG retrieves data from outside the language model (non-parametric) and augments the prompts by adding the relevant retrieved data in context. Here, we are performing RAG effectively on the knowledge base created using console/sdk. \n",
    "\n",
    "### Pre-requisite\n",
    "\n",
    "Before being able to answer the questions, the documents must be processed and ingested in vector database.\n",
    "\n",
    "1. Load the documents into the knowledge base by connecting your s3 bucket (data source). \n",
    "2. Ingestion - Knowledge bases will split them into smaller chunks (based on the strategy selected), generate embeddings and store it in the associated vectore store and notebook [0_create_ingest_documents_test_kb.ipynb](./0\\_create_ingest_documents_test_kb.ipynb) takes care of it for you.\n",
    "\n",
    "![data_ingestion](./images/data_ingestion.png)\n",
    "\n",
    "\n",
    "#### Notebook Walkthrough\n",
    "\n",
    "\n",
    "\n",
    "For our notebook we will use the `Retreive API` provided by Knowledge Bases for Amazon Bedrock which converts user queries into\n",
    "embeddings, searches the knowledge base, and returns the relevant results, giving you more control to build custom\n",
    "workﬂows on top of the semantic search results. The output of the `Retrieve API` includes the the `retrieved text chunks`, the `location type` and `URI` of the source data, as well as the relevance `scores` of the retrievals. \n",
    "\n",
    "\n",
    "We will then use the text chunks being generated and augment it with the original prompt and pass it through the `anthropic.claude-v2` model using prompt engineering patterns based on your use case.\n",
    "    \n",
    "\n",
    "### USE CASE:\n",
    "\n",
    "#### Dataset\n",
    "\n",
    "In this example, you will use several years of Amazon's Letter to Shareholders as a text corpus to perform Q&A on. This data is already ingested into the Knowledge Bases for Amazon Bedrock. You will need the `knowledge base id` to run this example.\n",
    "In your specific use case, you can sync different files for different domain topics and query this notebook in the same manner to evaluate model responses using the retrieve API from knowledge bases.\n",
    "\n",
    "\n",
    "### Python 3.10\n",
    "\n",
    "⚠  For this lab we need to run the notebook based on a Python 3.10 runtime. ⚠\n",
    "\n",
    "If you carry out the workshop from your local environment outside of the Amazon SageMaker studio please make sure you are running a Python runtime > 3.10.\n",
    "\n",
    "### Setup\n",
    "\n",
    "To run this notebook you would need to install following packages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (24.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "dash 2.17.1 requires dash-core-components==2.0.0, which is not installed.\n",
      "dash 2.17.1 requires dash-html-components==2.0.0, which is not installed.\n",
      "dash 2.17.1 requires dash-table==5.0.0, which is not installed.\n",
      "aiobotocore 2.13.1 requires botocore<1.34.132,>=1.34.70, but you have botocore 1.35.10 which is incompatible.\n",
      "amazon-sagemaker-sql-magic 0.1.3 requires sqlparse==0.5.0, but you have sqlparse 0.5.1 which is incompatible.\n",
      "autogluon-common 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-core 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-core 0.8.3 requires scikit-learn<1.4.1,>=1.1, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "autogluon-features 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-features 0.8.3 requires scikit-learn<1.4.1,>=1.1, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires pytorch-lightning<1.10.0,>=1.9.0, but you have pytorch-lightning 2.0.9 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires scikit-learn<1.4.1,>=1.1, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires torch<1.14,>=1.9, but you have torch 2.0.0.post104 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires torchmetrics<0.12.0,>=0.11.0, but you have torchmetrics 1.0.3 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires torchvision<0.15.0, but you have torchvision 0.15.2a0+ab7b3e6 which is incompatible.\n",
      "autogluon-tabular 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-tabular 0.8.3 requires scikit-learn<1.4.1,>=1.1, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "autogluon-timeseries 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-timeseries 0.8.3 requires pytorch-lightning<1.10.0,>=1.7.4, but you have pytorch-lightning 2.0.9 which is incompatible.\n",
      "autogluon-timeseries 0.8.3 requires torch<1.14,>=1.9, but you have torch 2.0.0.post104 which is incompatible.\n",
      "gluonts 0.13.7 requires pydantic~=1.7, but you have pydantic 2.8.2 which is incompatible.\n",
      "hdijupyterutils 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.1.4 which is incompatible.\n",
      "jupyter-ai-magics 2.20.0 requires langchain-community<0.3.0,>=0.1.0, but you have langchain-community 0.0.38 which is incompatible.\n",
      "langchain-aws 0.1.15 requires boto3<1.35.0,>=1.34.131, but you have boto3 1.35.10 which is incompatible.\n",
      "langchain-community 0.0.38 requires langchain-core<0.2.0,>=0.1.52, but you have langchain-core 0.2.37 which is incompatible.\n",
      "opensearch-py 2.3.1 requires urllib3<2,>=1.21.1, but you have urllib3 2.2.2 which is incompatible.\n",
      "sagemaker 2.227.0 requires attrs<24,>=23.1.0, but you have attrs 24.2.0 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.1.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Upgrade pip  \n",
    "%pip install --upgrade pip --no-cache-dir  \n",
    "# Force install dependencies with no cache  \n",
    "%pip install boto3 botocore langchain --force-reinstall --no-cache-dir --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restart the kernel with the updated packages that are installed through the dependencies above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follow the steps below to initiate the bedrock client:\n",
    "\n",
    "1. Import the necessary libraries, along with langchain for bedrock model selection, llama index to store the service context containing the llm and embedding model instances. We will use this service context later in the notebook for evaluating the responses from our Q&A application. \n",
    "\n",
    "2. Initialize `anthropic.claude-v2` as our large language model to perform query completions using the RAG pattern with the given knowledge base, once we get all text chunk searches through the `retrieve` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-west-2\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pprint\n",
    "from botocore.client import Config\n",
    "import json\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "bedrock_config = Config(connect_timeout=120, read_timeout=120, retries={'max_attempts': 0})\n",
    "bedrock_client = boto3.client('bedrock-runtime', region_name = region)\n",
    "bedrock_agent_client = boto3.client(\"bedrock-agent-runtime\",\n",
    "                              config=bedrock_config, region_name = region)\n",
    "print(region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 - Retrieve API with foundation models from Amazon Bedrock\n",
    "\n",
    "Define a retrieve function that calls the `Retreive API` provided by Knowledge Bases for Amazon Bedrock which converts user queries into\n",
    "embeddings, searches the knowledge base, and returns the relevant results, giving you more control to build custom\n",
    "workﬂows on top of the semantic search results. The output of the `Retrieve API` includes the the `retrieved text chunks`, the `location type` and `URI` of the source data, as well as the relevance `scores` of the retrievals. You can also use the  `overrideSearchType` option in `retrievalConfiguration` which offers the choice to use either `HYBRID` or `SEMANTIC`. By default, it will select the right strategy for you to give you most relevant results, and if you want to override the default option to use either hybrid or semantic search, you can set the value to `HYBRID/SEMANTIC`.\n",
    "\n",
    "![retrieveAPI](./images/retrieveAPI.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query, kbId, numberOfResults=5):\n",
    "    return bedrock_agent_client.retrieve(\n",
    "        retrievalQuery= {\n",
    "            'text': query\n",
    "        },\n",
    "        knowledgeBaseId=kbId,\n",
    "        retrievalConfiguration= {\n",
    "            'vectorSearchConfiguration': {\n",
    "                'numberOfResults': numberOfResults,\n",
    "                'overrideSearchType': \"HYBRID\", # optional\n",
    "            }\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize your Knowledge base id before querying responses from the initialized LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will call the `retreive API`, and pass `knowledge base id`, `number of results` and `query` as paramters. \n",
    "\n",
    "`score`: You can view the associated score of each of the text chunk that was returned which depicts its correlation to the query in terms of how closely it matches it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ { 'content': { 'text': 'ระเบียบวาระการประชุมคณะกรรมการบรหิาร สปสช. ครั้งท่ี '\n",
      "                         '๙/๒๕๖๖ วันท่ี ๒๗ มิถุนายน '\n",
      "                         '๒๕๖๖                                   '\n",
      "                         '๑/๒             ระเบียบวาระประชุมผู\\uf70bบริหาร '\n",
      "                         'สปสช. (Policy Advocacy Meeting: PAM) คร้ังที่ '\n",
      "                         '๒/๒๕๖๖  วันจันทร\\uf70eที่ ๑๐ กรกฎาคม ๒๕๖๖ เวลา ๑๓.๐๐ '\n",
      "                         '– ๑๖.๐๐ น.    ณ ห\\uf70bองประชุม ๒๐๒ ชั้น ๒ '\n",
      "                         'สำนักงานหลักประกันสขุภาพแห\\uf70aงชาติ '\n",
      "                         'และผ\\uf70aานสื่ออิเล็กทรอนิกส\\uf70e      o '\n",
      "                         'ประธานที่ประชุม : นพ. จเด็จ ธรรมธัชอารี  เลขาธิการ '\n",
      "                         'สปสช.'},\n",
      "    'location': { 's3Location': { 'uri': 's3://bedrock-kb-us-west-2-615631871157/0_วาระการประชุม '\n",
      "                                         'PAM 2_66.pdf'},\n",
      "                  'type': 'S3'},\n",
      "    'score': 0.57546735},\n",
      "  { 'content': { 'text': 'ขอความร\\uf70aวมมือผู\\uf70bนำเสนอ นำเสนอแบบกระชบั '\n",
      "                         'ภายใน 5 นาที ประกอบด\\uf70bวย ที่มา '\n",
      "                         'สรุปข\\uf70bอมูลสำคัญประกอบข\\uf70bอเสนอ  และ '\n",
      "                         'ข\\uf70bอเสนอเพื่อพิจารณา/เพื่อทราบ และสำรองเวลา '\n",
      "                         'สำหรับการอภิปรายและแลกเปลีย่นความเห็น  ๒. '\n",
      "                         'ระเบียบวาระและเอกสารประกอบการประชุม วางไว\\uf70bที ่ '\n",
      "                         '1. T:\\\\PAU meeting\\\\04 '\n",
      "                         'ประชมุคณะกรรมการบริหาร\\\\เอกสารประกอบการประชุม\\\\2566\\\\กก.บ '\n",
      "                         '9_2566  2. '\n",
      "                         'https://drive.google.com/drive/folders/1Atv6E_J6v4_Z3K63p6mDYTMFk2sMmMV_?usp=drive_link'},\n",
      "    'location': { 's3Location': { 'uri': 's3://bedrock-kb-us-west-2-615631871157/0_วาระการประชุม '\n",
      "                                         'PAM 2_66.pdf'},\n",
      "                  'type': 'S3'},\n",
      "    'score': 0.57546735},\n",
      "  { 'content': { 'text': 'o นายทรงกรด เกษกาญจนานุช  '\n",
      "                         'ฝ\\uf705ายสนับสนุนนโยบายด\\uf70bานเทคโนโลยสีารสนเทศ    '\n",
      "                         'o นายปริญัติ ลิมป\\uf701ทีปราการ  '\n",
      "                         'ฝ\\uf705ายนวัตกรรมข\\uf70bอมูลอัจฉริยะ      '\n",
      "                         'ระเบียบวาระที่ ๕ เร่ืองเพ่ือทราบ          '\n",
      "                         'ระเบียบวาระการประชุมคณะกรรมการบรหิาร สปสช.'},\n",
      "    'location': { 's3Location': { 'uri': 's3://bedrock-kb-us-west-2-615631871157/0_วาระการประชุม '\n",
      "                                         'PAM 2_66.pdf'},\n",
      "                  'type': 'S3'},\n",
      "    'score': 0.56216973},\n",
      "  { 'content': { 'text': 'ประธาน/เลขานุการ แจ้งให้ที่ประชุมทราบ 1 เรื่อง '\n",
      "                         'ดังนี้  การแต่งตั้งคณะอนุกรรมการก '\n",
      "                         'ากับทิศทางสถาบันวิจัยเพื่อความเสมอภาคทางการศึกษา  '\n",
      "                         'ตามที่คณะอนุกรรมการก '\n",
      "                         'ากับทิศทางสถาบันวิจัยเพื่อความเสมอภาคทางการศึกษา '\n",
      "                         'ซึ่งได้รับการ   แต่งตั ้งตามค าสั '\n",
      "                         '่งคณะกรรมการบริหารกองทุนเพื ่อความเสมอภาคทางการศึกษา '\n",
      "                         'ที ่ 2/2566 เมื ่อวันที่   22 พฤษภาคม พ.ศ. 2566 '\n",
      "                         'ได้ครบก าหนดการปฏิบัติหน้าที่เม่ือวันที่ 31 กรกฎาคม '\n",
      "                         '2567 นั้น    อาศัยอ านาจตามความในมาตรา 23(10) '\n",
      "                         'แห่งพระราชบัญญัติกองทุนเพื่อความเสมอภาคทาง การศึกษา '\n",
      "                         'พ.ศ. 2561 คณะกรรมการบริหารกองทุนเพื'},\n",
      "    'location': { 's3Location': { 'uri': 's3://bedrock-kb-us-west-2-615631871157/Final_เอกสารประกอบวาระอนุกรรมการ '\n",
      "                                         'วสศ. ครั้งที่ 3_2567.pdf'},\n",
      "                  'type': 'S3'},\n",
      "    'score': 0.5488174},\n",
      "  { 'content': { 'text': 'รองเลขาธิการ  o นางสาวอมรรัตน\\uf70e '\n",
      "                         'เงาวะบุญพัฒน\\uf70e    '\n",
      "                         'ฝ\\uf705ายกำกับติดตามประเมินผล    ๔.๒ '\n",
      "                         'วิธีการจัดการความเส่ียง o นายพรรคพงศ\\uf70e '\n",
      "                         'วุฒิวงศ\\uf70e   '\n",
      "                         'ฝ\\uf705ายบริหารและพัฒนาทรัพยากรบุคคล      ๔.๓ '\n",
      "                         '(ร\\uf70aาง) ประกาศเกษียณก\\uf70aอนอายุราชการ o '\n",
      "                         'นางสาวณัฐณภัค ลุผล  ผู\\uf70bอำนวยการฝ\\uf705าย '\n",
      "                         'ฝ\\uf705ายบริหารและพัฒนา ทรัพยากรบุคคล      ๔.๔ '\n",
      "                         'ทบทวนวรรณกรรมท่ีเกี่ยวข\\uf70bองกับระบบ Cyber  '\n",
      "                         'Security การเตรียมรับมือภัยคุกคาม และเทคโนโลยีท่ี '\n",
      "                         'เกี่ยวข\\uf70bอง    o นายประเทือง เผ\\uf70aาดิษฐ  '\n",
      "                         'ผู\\uf70bช\\uf70aวยเลขาธิการ สปสช.'},\n",
      "    'location': { 's3Location': { 'uri': 's3://bedrock-kb-us-west-2-615631871157/0_วาระการประชุม '\n",
      "                                         'PAM 2_66.pdf'},\n",
      "                  'type': 'S3'},\n",
      "    'score': 0.5464704}]\n"
     ]
    }
   ],
   "source": [
    "query = \"วาระประชุม PAM ล่าสุดมีอะไรบ้าง?\"\n",
    "response = retrieve(query, kb_id, 5)\n",
    "retrievalResults = response['retrievalResults']\n",
    "pp.pprint(retrievalResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the text chunks from the retrieveAPI response\n",
    "\n",
    "In the cell below, we will fetch the context from the retrieval results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch context from the response\n",
    "def get_contexts(retrievalResults):\n",
    "    contexts = []\n",
    "    for retrievedResult in retrievalResults: \n",
    "        contexts.append(retrievedResult['content']['text'])\n",
    "    return contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 'ระเบียบวาระการประชุมคณะกรรมการบรหิาร สปสช. ครั้งท่ี ๙/๒๕๖๖ วันท่ี ๒๗ '\n",
      "  'มิถุนายน ๒๕๖๖                                   ๑/๒             '\n",
      "  'ระเบียบวาระประชุมผู\\uf70bบริหาร สปสช. (Policy Advocacy Meeting: PAM) '\n",
      "  'คร้ังที่ ๒/๒๕๖๖  วันจันทร\\uf70eที่ ๑๐ กรกฎาคม ๒๕๖๖ เวลา ๑๓.๐๐ – ๑๖.๐๐ น.    '\n",
      "  'ณ ห\\uf70bองประชุม ๒๐๒ ชั้น ๒ สำนักงานหลักประกันสขุภาพแห\\uf70aงชาติ '\n",
      "  'และผ\\uf70aานสื่ออิเล็กทรอนิกส\\uf70e      o ประธานที่ประชุม : นพ. จเด็จ '\n",
      "  'ธรรมธัชอารี  เลขาธิการ สปสช.',\n",
      "  'ขอความร\\uf70aวมมือผู\\uf70bนำเสนอ นำเสนอแบบกระชบั ภายใน 5 นาที '\n",
      "  'ประกอบด\\uf70bวย ที่มา สรุปข\\uf70bอมูลสำคัญประกอบข\\uf70bอเสนอ  และ '\n",
      "  'ข\\uf70bอเสนอเพื่อพิจารณา/เพื่อทราบ และสำรองเวลา '\n",
      "  'สำหรับการอภิปรายและแลกเปลีย่นความเห็น  ๒. '\n",
      "  'ระเบียบวาระและเอกสารประกอบการประชุม วางไว\\uf70bที ่ 1. T:\\\\PAU meeting\\\\04 '\n",
      "  'ประชมุคณะกรรมการบริหาร\\\\เอกสารประกอบการประชุม\\\\2566\\\\กก.บ 9_2566  2. '\n",
      "  'https://drive.google.com/drive/folders/1Atv6E_J6v4_Z3K63p6mDYTMFk2sMmMV_?usp=drive_link',\n",
      "  'o นายทรงกรด เกษกาญจนานุช  '\n",
      "  'ฝ\\uf705ายสนับสนุนนโยบายด\\uf70bานเทคโนโลยสีารสนเทศ    o นายปริญัติ '\n",
      "  'ลิมป\\uf701ทีปราการ  ฝ\\uf705ายนวัตกรรมข\\uf70bอมูลอัจฉริยะ      '\n",
      "  'ระเบียบวาระที่ ๕ เร่ืองเพ่ือทราบ          '\n",
      "  'ระเบียบวาระการประชุมคณะกรรมการบรหิาร สปสช.',\n",
      "  'ประธาน/เลขานุการ แจ้งให้ที่ประชุมทราบ 1 เรื่อง ดังนี้  '\n",
      "  'การแต่งตั้งคณะอนุกรรมการก ากับทิศทางสถาบันวิจัยเพื่อความเสมอภาคทางการศึกษา  '\n",
      "  'ตามที่คณะอนุกรรมการก ากับทิศทางสถาบันวิจัยเพื่อความเสมอภาคทางการศึกษา '\n",
      "  'ซึ่งได้รับการ   แต่งตั ้งตามค าสั ่งคณะกรรมการบริหารกองทุนเพื '\n",
      "  '่อความเสมอภาคทางการศึกษา ที ่ 2/2566 เมื ่อวันที่   22 พฤษภาคม พ.ศ. 2566 '\n",
      "  'ได้ครบก าหนดการปฏิบัติหน้าที่เม่ือวันที่ 31 กรกฎาคม 2567 นั้น    อาศัยอ '\n",
      "  'านาจตามความในมาตรา 23(10) แห่งพระราชบัญญัติกองทุนเพื่อความเสมอภาคทาง '\n",
      "  'การศึกษา พ.ศ. 2561 คณะกรรมการบริหารกองทุนเพื',\n",
      "  'รองเลขาธิการ  o นางสาวอมรรัตน\\uf70e เงาวะบุญพัฒน\\uf70e    '\n",
      "  'ฝ\\uf705ายกำกับติดตามประเมินผล    ๔.๒ วิธีการจัดการความเส่ียง o '\n",
      "  'นายพรรคพงศ\\uf70e วุฒิวงศ\\uf70e   ฝ\\uf705ายบริหารและพัฒนาทรัพยากรบุคคล      '\n",
      "  '๔.๓ (ร\\uf70aาง) ประกาศเกษียณก\\uf70aอนอายุราชการ o นางสาวณัฐณภัค ลุผล  '\n",
      "  'ผู\\uf70bอำนวยการฝ\\uf705าย ฝ\\uf705ายบริหารและพัฒนา ทรัพยากรบุคคล      ๔.๔ '\n",
      "  'ทบทวนวรรณกรรมท่ีเกี่ยวข\\uf70bองกับระบบ Cyber  Security '\n",
      "  'การเตรียมรับมือภัยคุกคาม และเทคโนโลยีท่ี เกี่ยวข\\uf70bอง    o นายประเทือง '\n",
      "  'เผ\\uf70aาดิษฐ  ผู\\uf70bช\\uf70aวยเลขาธิการ สปสช.']\n"
     ]
    }
   ],
   "source": [
    "contexts = get_contexts(retrievalResults)\n",
    "pp.pprint(contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt specific to the model to personalize responses \n",
    "\n",
    "Here, we will use the specific prompt below for the model to act as a financial advisor AI system that will provide answers to questions by using fact based and statistical information when possible. We will provide the `Retrieve API` responses from above as a part of the `{contexts}` in the prompt for the model to refer to, along with the user `query`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Human: You are a secretariat of PAM meetings, and provides answers to questions by using fact based and statistical information when possible. \n",
    "Use the following pieces of information to provide a concise answer to the question enclosed in <question> tags. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "<context>\n",
    "{contexts}\n",
    "</context>\n",
    "\n",
    "<question>\n",
    "{query}\n",
    "</question>\n",
    "\n",
    "The response should be specific and use statistics or numbers when possible.\n",
    "\n",
    "Assistant:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke foundation model from Amazon Bedrock\n",
    "In this example, we will use `mistral.mistral-7b` foundation model from Amazon Bedrock. \n",
    "Its a 7B dense Transformer, fast-deployed and easily customizable. Small, yet powerful for a variety of use cases.\n",
    "- Max tokens: 8K\n",
    "- Languages: English\n",
    "- Supported use cases: Text summarization, structuration, question answering, and code completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# payload with model paramters\n",
    "mistral_payload = json.dumps({\n",
    "    \"prompt\": prompt,\n",
    "    \"max_tokens\":512,\n",
    "    \"temperature\":0.5,\n",
    "    \"top_k\":50,\n",
    "    \"top_p\":0.9\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> Please make sure you have subscribed to the <b>mistral-7B</b> model on the model access page in the Amazon Bedrock console before proceeding.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' Based on the context provided, the last PAM meeting took place on August '\n",
      " '27, 2023, from 1:30 PM to 2:00 PM, at the Office of the Permanent Secretary, '\n",
      " 'Ministry of Finance, and the meeting was chaired by H.E. Thammarat '\n",
      " 'Kittisiriprasert, Secretary-General of the Sports and Tourism Ministry. The '\n",
      " 'agenda included discussing the appointment of the committee for alignment '\n",
      " 'with the direction of educational institutions, as per the decision of the '\n",
      " 'Educational Institutions Committee. This appointment was made on February '\n",
      " \"22, 2026, and the committee's duties were completed by November 30, 2027, in \"\n",
      " 'accordance with the 23(10) Law on Educational Funds.\\n'\n",
      " '\\n'\n",
      " 'The meeting also involved discussions on managing conflicts, led by Mr. '\n",
      " 'Phongphong Wuthivong, Director of the Legal Department, and Mr. Nathapong '\n",
      " 'Luphol, Deputy Secretary-General of the Sports and Tourism Ministry. The '\n",
      " 'agenda also included matters related to cybersecurity and technology, as '\n",
      " 'well as retirement age for civil servants, represented by Ms. Omrattana '\n",
      " 'Boonphan and Ms. Nattawut Wattanarat, respectively.\\n'\n",
      " '\\n'\n",
      " 'Therefore, the last PAM meeting covered important topics such as committee '\n",
      " 'appointments, managing conflicts, cybersecurity, technology, and retirement '\n",
      " 'age for civil servants.')\n"
     ]
    }
   ],
   "source": [
    "modelId = 'mistral.mistral-7b-instruct-v0:2' # change this to use a different version from the model provider\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "response = bedrock_client.invoke_model(body=mistral_payload, modelId=modelId, accept=accept, contentType=contentType)\n",
    "response_body = json.loads(response.get('body').read())\n",
    "response_text = response_body.get('outputs')[0]['text']\n",
    "\n",
    "pp.pprint(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - LangChain integration\n",
    "In this notebook, we will dive deep into building Q&A application using Retrieve API provided by Knowledge Bases for Amazon Bedrock and LangChain. We will query the knowledge base to get the desired number of document chunks based on similarity search, integrate it with LangChain retriever and use Anthropic Claude V2.1 model for answering questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'UsageMetadata' from 'langchain_core.messages.ai' (/opt/conda/lib/python3.10/site-packages/langchain_core/messages/ai.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_aws\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatBedrock\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mretrievers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbedrock\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AmazonKnowledgeBasesRetriever\n\u001b[1;32m      4\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatBedrock(model_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manthropic.claude-3-haiku-20240307-v1:0\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m               client \u001b[38;5;241m=\u001b[39m bedrock_client)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_aws/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_aws\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BedrockChat, ChatBedrock, ChatBedrockConverse\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_aws\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BedrockEmbeddings\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_aws\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraphs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NeptuneAnalyticsGraph, NeptuneGraph\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_aws/chat_models/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_aws\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbedrock\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BedrockChat, ChatBedrock\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_aws\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbedrock_converse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatBedrockConverse\n\u001b[1;32m      4\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBedrockChat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatBedrock\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatBedrockConverse\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_aws/chat_models/bedrock.py:30\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate_from_stream\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     AIMessage,\n\u001b[1;32m     24\u001b[0m     AIMessageChunk,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m     SystemMessage,\n\u001b[1;32m     29\u001b[0m )\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UsageMetadata\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtool\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ToolCall, ToolMessage\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutputs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatGeneration, ChatGenerationChunk, ChatResult\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'UsageMetadata' from 'langchain_core.messages.ai' (/opt/conda/lib/python3.10/site-packages/langchain_core/messages/ai.py)"
     ]
    }
   ],
   "source": [
    "from langchain_aws import ChatBedrock\n",
    "from langchain.retrievers.bedrock import AmazonKnowledgeBasesRetriever\n",
    "\n",
    "llm = ChatBedrock(model_id=\"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "              client = bedrock_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `AmazonKnowledgeBasesRetriever` object from LangChain which will call the `Retreive API` provided by Knowledge Bases for Amazon Bedrock which converts user queries into embeddings, searches the knowledge base, and returns the relevant results, giving you more control to build custom workﬂows on top of the semantic search results. The output of the `Retrieve API` includes the the `retrieved text chunks`, the `location type` and `URI` of the source data, as well as the relevance `scores` of the retrievals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"By what percentage did AWS revenue grow year-over-year in 2022?\"\n",
    "retriever = AmazonKnowledgeBasesRetriever(\n",
    "        knowledge_base_id=kb_id,\n",
    "        retrieval_config={\"vectorSearchConfiguration\": \n",
    "                          {\"numberOfResults\": 4,\n",
    "                           'overrideSearchType': \"SEMANTIC\", # optional\n",
    "                           }\n",
    "                          },\n",
    "        # endpoint_url=endpoint_url,\n",
    "        # region_name=region,\n",
    "        # credentials_profile_name=\"<profile_name>\",\n",
    "    )\n",
    "docs = retriever.get_relevant_documents(\n",
    "        query=query\n",
    "    )\n",
    "pp.pprint(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt specific to the model to personalize responses\n",
    "Here, we will use the specific prompt below for the model to act as a financial advisor AI system that will provide answers to questions by using fact based and statistical information when possible. We will provide the Retrieve API responses from above as a part of the `{context}` in the prompt for the model to refer to, along with the user `query`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Human: You are a financial advisor AI system, and provides answers to questions by using fact based and statistical information when possible. \n",
    "Use the following pieces of information to provide a concise answer to the question enclosed in <question> tags. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\n",
    "The response should be specific and use statistics or numbers when possible.\n",
    "\n",
    "Assistant:\"\"\"\n",
    "claude_prompt = PromptTemplate(template=PROMPT_TEMPLATE, \n",
    "                               input_variables=[\"context\",\"question\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrating the retriever and the LLM defined above with RetrievalQA Chain to build the Q&A application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": claude_prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = qa.invoke(query)\n",
    "pp.pprint(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "You can use Retrieve API for customizing your RAG based application, using either `InvokeModel` API from Bedrock, or you can integrate with LangChain using `AmazonKnowledgeBaseRetriever`.\n",
    "Retrieve API provides you with the flexibility of using any foundation model provided by Amazon Bedrock, and choosing the right search type, either HYBRID or SEMANTIC, based on your use case. \n",
    "Here is the [blog](#https://aws.amazon.com/blogs/machine-learning/knowledge-bases-for-amazon-bedrock-now-supports-hybrid-search/) for Hybrid Search feature, for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b> Remember to CLEAN_UP at the end of your session. </b>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

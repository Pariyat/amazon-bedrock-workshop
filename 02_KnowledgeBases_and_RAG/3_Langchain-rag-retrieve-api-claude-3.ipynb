{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Q&A application using Knowledge Bases for Amazon Bedrock - Retrieve API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> This lab uses Anthropic Claude v3, which is not available in AWS Workshop Studio yet. You may\n",
    "    continue with this lab if the account you are running this in has access to Claude V3.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context\n",
    "\n",
    "In this notebook, we will dive deep into building Q&A application using Knowledge Bases for Amazon Bedrock - Retrieve API. Here, we will query the knowledge base to get the desired number of document chunks based on similarity search. We will then augment the prompt with relevant documents and query which will go as input to Anthropic Claude V2 for generating response.\n",
    "\n",
    "With a knowledge base, you can securely connect foundation models (FMs) in Amazon Bedrock to your company\n",
    "data for Retrieval Augmented Generation (RAG). Access to additional data helps the model generate more relevant,\n",
    "context-speciﬁc, and accurate responses without continuously retraining the FM. All information retrieved from\n",
    "knowledge bases comes with source attribution to improve transparency and minimize hallucinations. For more information on creating a knowledge base using console, please refer to this [post](https://docs.aws.amazon.com/bedrock/latest/userguide/knowledge-base.html).\n",
    "We will cover 2 parts in the notebook:\n",
    "- Part 1, we will share how you can use `RetrieveAPI` with foundation models from Amazon Bedrock. We will use the `anthropic.claude-3-sonnet-20240229-v1:0` model. \n",
    "- Part 2, we will showcase the langchain integration.\n",
    "\n",
    "### Pattern\n",
    "\n",
    "We can implement the solution using Retreival Augmented Generation (RAG) pattern. RAG retrieves data from outside the language model (non-parametric) and augments the prompts by adding the relevant retrieved data in context. Here, we are performing RAG effectively on the knowledge base created using console/sdk. \n",
    "\n",
    "### Pre-requisite\n",
    "\n",
    "Before being able to answer the questions, the documents must be processed and ingested in vector database.\n",
    "\n",
    "1. Load the documents into the knowledge base by connecting your s3 bucket (data source). \n",
    "2. Ingestion - Knowledge bases will split them into smaller chunks (based on the strategy selected), generate embeddings and store it in the associated vectore store and notebook [0_create_ingest_documents_test_kb.ipynb](./0\\_create_ingest_documents_test_kb.ipynb) takes care of it for you.\n",
    "\n",
    "![data_ingestion](./images/data_ingestion.png)\n",
    "\n",
    "\n",
    "#### Notebook Walkthrough\n",
    "\n",
    "\n",
    "\n",
    "For our notebook we will use the `Retreive API` provided by Knowledge Bases for Amazon Bedrock which converts user queries into\n",
    "embeddings, searches the knowledge base, and returns the relevant results, giving you more control to build custom\n",
    "workﬂows on top of the semantic search results. The output of the `Retrieve API` includes the the `retrieved text chunks`, the `location type` and `URI` of the source data, as well as the relevance `scores` of the retrievals. \n",
    "\n",
    "\n",
    "We will then use the text chunks being generated and augment it with the original prompt and pass it through the `anthropic.claude-3-sonnet-20240229-v1:0` model using prompt engineering patterns based on your use case.\n",
    "    \n",
    "\n",
    "### USE CASE:\n",
    "\n",
    "#### Dataset\n",
    "\n",
    "In this example, you will use several years of Amazon's Letter to Shareholders as a text corpus to perform Q&A on. This data is already ingested into the Knowledge Bases for Amazon Bedrock. You will need the `knowledge base id` to run this example.\n",
    "In your specific use case, you can sync different files for different domain topics and query this notebook in the same manner to evaluate model responses using the retrieve API from knowledge bases.\n",
    "\n",
    "\n",
    "### Python 3.10\n",
    "\n",
    "⚠  For this lab we need to run the notebook based on a Python 3.10 runtime. ⚠\n",
    "\n",
    "If you carry out the workshop from your local environment outside of the Amazon SageMaker studio please make sure you are running a Python runtime > 3.10.\n",
    "\n",
    "### Setup\n",
    "\n",
    "To run this notebook you would need to install following packages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (24.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.13.1 requires botocore<1.34.132,>=1.34.70, but you have botocore 1.35.10 which is incompatible.\n",
      "amazon-sagemaker-sql-magic 0.1.3 requires sqlparse==0.5.0, but you have sqlparse 0.5.1 which is incompatible.\n",
      "autogluon-common 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-core 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-core 0.8.3 requires scikit-learn<1.4.1,>=1.1, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "autogluon-features 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-features 0.8.3 requires scikit-learn<1.4.1,>=1.1, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires pytorch-lightning<1.10.0,>=1.9.0, but you have pytorch-lightning 2.0.9 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires scikit-learn<1.4.1,>=1.1, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires torch<1.14,>=1.9, but you have torch 2.0.0.post104 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires torchmetrics<0.12.0,>=0.11.0, but you have torchmetrics 1.0.3 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires torchvision<0.15.0, but you have torchvision 0.15.2a0+ab7b3e6 which is incompatible.\n",
      "autogluon-tabular 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-tabular 0.8.3 requires scikit-learn<1.4.1,>=1.1, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "autogluon-timeseries 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-timeseries 0.8.3 requires pytorch-lightning<1.10.0,>=1.7.4, but you have pytorch-lightning 2.0.9 which is incompatible.\n",
      "autogluon-timeseries 0.8.3 requires torch<1.14,>=1.9, but you have torch 2.0.0.post104 which is incompatible.\n",
      "langchain-aws 0.1.15 requires boto3<1.35.0,>=1.34.131, but you have boto3 1.35.10 which is incompatible.\n",
      "opensearch-py 2.3.1 requires urllib3<2,>=1.21.1, but you have urllib3 2.2.2 which is incompatible.\n",
      "sagemaker 2.227.0 requires attrs<24,>=23.1.0, but you have attrs 24.2.0 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.1.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.13.1 requires botocore<1.34.132,>=1.34.70, but you have botocore 1.35.10 which is incompatible.\n",
      "langchain-aws 0.1.15 requires boto3<1.35.0,>=1.34.131, but you have boto3 1.35.10 which is incompatible.\n",
      "opensearch-py 2.3.1 requires urllib3<2,>=1.21.1, but you have urllib3 2.2.2 which is incompatible.\n",
      "sagemaker 2.227.0 requires attrs<24,>=23.1.0, but you have attrs 24.2.0 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.1.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "dash 2.17.1 requires dash-core-components==2.0.0, which is not installed.\n",
      "dash 2.17.1 requires dash-html-components==2.0.0, which is not installed.\n",
      "dash 2.17.1 requires dash-table==5.0.0, which is not installed.\n",
      "aiobotocore 2.13.1 requires botocore<1.34.132,>=1.34.70, but you have botocore 1.35.10 which is incompatible.\n",
      "autogluon-common 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-core 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-core 0.8.3 requires scikit-learn<1.4.1,>=1.1, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "autogluon-features 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-features 0.8.3 requires scikit-learn<1.4.1,>=1.1, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires pytorch-lightning<1.10.0,>=1.9.0, but you have pytorch-lightning 2.0.9 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires scikit-learn<1.4.1,>=1.1, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires torch<1.14,>=1.9, but you have torch 2.0.0.post104 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires torchmetrics<0.12.0,>=0.11.0, but you have torchmetrics 1.0.3 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires torchvision<0.15.0, but you have torchvision 0.15.2a0+ab7b3e6 which is incompatible.\n",
      "autogluon-tabular 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-tabular 0.8.3 requires scikit-learn<1.4.1,>=1.1, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "autogluon-timeseries 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-timeseries 0.8.3 requires pytorch-lightning<1.10.0,>=1.7.4, but you have pytorch-lightning 2.0.9 which is incompatible.\n",
      "autogluon-timeseries 0.8.3 requires torch<1.14,>=1.9, but you have torch 2.0.0.post104 which is incompatible.\n",
      "gluonts 0.13.7 requires pydantic~=1.7, but you have pydantic 2.8.2 which is incompatible.\n",
      "hdijupyterutils 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.1.4 which is incompatible.\n",
      "jupyter-ai-magics 2.20.0 requires langchain-community<0.3.0,>=0.1.0, but you have langchain-community 0.0.38 which is incompatible.\n",
      "langchain-aws 0.1.15 requires boto3<1.35.0,>=1.34.131, but you have boto3 1.35.10 which is incompatible.\n",
      "langchain-community 0.0.38 requires langchain-core<0.2.0,>=0.1.52, but you have langchain-core 0.2.37 which is incompatible.\n",
      "opensearch-py 2.3.1 requires urllib3<2,>=1.21.1, but you have urllib3 2.2.2 which is incompatible.\n",
      "sagemaker 2.227.0 requires attrs<24,>=23.1.0, but you have attrs 24.2.0 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.1.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install boto3 --force-reinstall --quiet\n",
    "%pip install botocore --force-reinstall --quiet\n",
    "%pip install langchain --force-reinstall --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restart the kernel with the updated packages that are installed through the dependencies above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follow the steps below to initiate the bedrock client:\n",
    "\n",
    "1. Import the necessary libraries, along with langchain for bedrock model selection, llama index to store the service context containing the llm and embedding model instances. We will use this service context later in the notebook for evaluating the responses from our Q&A application. \n",
    "\n",
    "2. Initialize `anthropic.claude-3-sonnet-20240229-v1:0` as our large language model to perform query completions using the RAG pattern with the given knowledge base, once we get all text chunk searches through the `retrieve` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-west-2\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pprint\n",
    "from botocore.client import Config\n",
    "import json\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "bedrock_config = Config(connect_timeout=120, read_timeout=120, retries={'max_attempts': 0})\n",
    "bedrock_client = boto3.client('bedrock-runtime', region_name = region)\n",
    "bedrock_agent_client = boto3.client(\"bedrock-agent-runtime\",\n",
    "                              config=bedrock_config, region_name = region)\n",
    "print(region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 - Retrieve API with foundation models from Amazon Bedrock\n",
    "\n",
    "Define a retrieve function that calls the `Retreive API` provided by Knowledge Bases for Amazon Bedrock which converts user queries into\n",
    "embeddings, searches the knowledge base, and returns the relevant results, giving you more control to build custom\n",
    "workﬂows on top of the semantic search results. The output of the `Retrieve API` includes the the `retrieved text chunks`, the `location type` and `URI` of the source data, as well as the relevance `scores` of the retrievals. You can also use the  `overrideSearchType` option in `retrievalConfiguration` which offers the choice to use either `HYBRID` or `SEMANTIC`. By default, it will select the right strategy for you to give you most relevant results, and if you want to override the default option to use either hybrid or semantic search, you can set the value to `HYBRID/SEMANTIC`.\n",
    "\n",
    "![retrieveAPI](./images/retrieveAPI.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query, kbId, numberOfResults=5):\n",
    "    return bedrock_agent_client.retrieve(\n",
    "        retrievalQuery= {\n",
    "            'text': query\n",
    "        },\n",
    "        knowledgeBaseId=kbId,\n",
    "        retrievalConfiguration= {\n",
    "            'vectorSearchConfiguration': {\n",
    "                'numberOfResults': numberOfResults,\n",
    "                'overrideSearchType': \"HYBRID\", # optional\n",
    "            }\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize your Knowledge base id before querying responses from the initialized LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will call the `retreive API`, and pass `knowledge base id`, `number of results` and `query` as paramters. \n",
    "\n",
    "`score`: You can view the associated score of each of the text chunk that was returned which depicts its correlation to the query in terms of how closely it matches it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ { 'content': { 'text': 'ระเบียบวาระการประชุมคณะกรรมการบรหิาร สปสช. ครั้งท่ี '\n",
      "                         '๙/๒๕๖๖ วันท่ี ๒๗ มิถุนายน '\n",
      "                         '๒๕๖๖                                   '\n",
      "                         '๑/๒             ระเบียบวาระประชุมผู\\uf70bบริหาร '\n",
      "                         'สปสช. (Policy Advocacy Meeting: PAM) คร้ังที่ '\n",
      "                         '๒/๒๕๖๖  วันจันทร\\uf70eที่ ๑๐ กรกฎาคม ๒๕๖๖ เวลา ๑๓.๐๐ '\n",
      "                         '– ๑๖.๐๐ น.    ณ ห\\uf70bองประชุม ๒๐๒ ชั้น ๒ '\n",
      "                         'สำนักงานหลักประกันสขุภาพแห\\uf70aงชาติ '\n",
      "                         'และผ\\uf70aานสื่ออิเล็กทรอนิกส\\uf70e      o '\n",
      "                         'ประธานที่ประชุม : นพ. จเด็จ ธรรมธัชอารี  เลขาธิการ '\n",
      "                         'สปสช.'},\n",
      "    'location': { 's3Location': { 'uri': 's3://bedrock-kb-us-west-2-615631871157/0_วาระการประชุม '\n",
      "                                         'PAM 2_66.pdf'},\n",
      "                  'type': 'S3'},\n",
      "    'metadata': { 'x-amz-bedrock-kb-chunk-id': '1%3A0%3AbFO_tpEB4MOf1e-P1ZJc',\n",
      "                  'x-amz-bedrock-kb-data-source-id': 'OGRCYT4JHB',\n",
      "                  'x-amz-bedrock-kb-source-uri': 's3://bedrock-kb-us-west-2-615631871157/0_วาระการประชุม '\n",
      "                                                 'PAM 2_66.pdf'},\n",
      "    'score': 0.57546735},\n",
      "  { 'content': { 'text': 'ขอความร\\uf70aวมมือผู\\uf70bนำเสนอ นำเสนอแบบกระชบั '\n",
      "                         'ภายใน 5 นาที ประกอบด\\uf70bวย ที่มา '\n",
      "                         'สรุปข\\uf70bอมูลสำคัญประกอบข\\uf70bอเสนอ  และ '\n",
      "                         'ข\\uf70bอเสนอเพื่อพิจารณา/เพื่อทราบ และสำรองเวลา '\n",
      "                         'สำหรับการอภิปรายและแลกเปลีย่นความเห็น  ๒. '\n",
      "                         'ระเบียบวาระและเอกสารประกอบการประชุม วางไว\\uf70bที ่ '\n",
      "                         '1. T:\\\\PAU meeting\\\\04 '\n",
      "                         'ประชมุคณะกรรมการบริหาร\\\\เอกสารประกอบการประชุม\\\\2566\\\\กก.บ '\n",
      "                         '9_2566  2. '\n",
      "                         'https://drive.google.com/drive/folders/1Atv6E_J6v4_Z3K63p6mDYTMFk2sMmMV_?usp=drive_link'},\n",
      "    'location': { 's3Location': { 'uri': 's3://bedrock-kb-us-west-2-615631871157/0_วาระการประชุม '\n",
      "                                         'PAM 2_66.pdf'},\n",
      "                  'type': 'S3'},\n",
      "    'metadata': { 'x-amz-bedrock-kb-chunk-id': '1%3A0%3AclO_tpEB4MOf1e-P1ZJd',\n",
      "                  'x-amz-bedrock-kb-data-source-id': 'OGRCYT4JHB',\n",
      "                  'x-amz-bedrock-kb-source-uri': 's3://bedrock-kb-us-west-2-615631871157/0_วาระการประชุม '\n",
      "                                                 'PAM 2_66.pdf'},\n",
      "    'score': 0.57546735},\n",
      "  { 'content': { 'text': 'o นายทรงกรด เกษกาญจนานุช  '\n",
      "                         'ฝ\\uf705ายสนับสนุนนโยบายด\\uf70bานเทคโนโลยสีารสนเทศ    '\n",
      "                         'o นายปริญัติ ลิมป\\uf701ทีปราการ  '\n",
      "                         'ฝ\\uf705ายนวัตกรรมข\\uf70bอมูลอัจฉริยะ      '\n",
      "                         'ระเบียบวาระที่ ๕ เร่ืองเพ่ือทราบ          '\n",
      "                         'ระเบียบวาระการประชุมคณะกรรมการบรหิาร สปสช.'},\n",
      "    'location': { 's3Location': { 'uri': 's3://bedrock-kb-us-west-2-615631871157/0_วาระการประชุม '\n",
      "                                         'PAM 2_66.pdf'},\n",
      "                  'type': 'S3'},\n",
      "    'metadata': { 'x-amz-bedrock-kb-chunk-id': '1%3A0%3AcFO_tpEB4MOf1e-P1ZJc',\n",
      "                  'x-amz-bedrock-kb-data-source-id': 'OGRCYT4JHB',\n",
      "                  'x-amz-bedrock-kb-source-uri': 's3://bedrock-kb-us-west-2-615631871157/0_วาระการประชุม '\n",
      "                                                 'PAM 2_66.pdf'},\n",
      "    'score': 0.56216973},\n",
      "  { 'content': { 'text': 'ประธาน/เลขานุการ แจ้งให้ที่ประชุมทราบ 1 เรื่อง '\n",
      "                         'ดังนี้  การแต่งตั้งคณะอนุกรรมการก '\n",
      "                         'ากับทิศทางสถาบันวิจัยเพื่อความเสมอภาคทางการศึกษา  '\n",
      "                         'ตามที่คณะอนุกรรมการก '\n",
      "                         'ากับทิศทางสถาบันวิจัยเพื่อความเสมอภาคทางการศึกษา '\n",
      "                         'ซึ่งได้รับการ   แต่งตั ้งตามค าสั '\n",
      "                         '่งคณะกรรมการบริหารกองทุนเพื ่อความเสมอภาคทางการศึกษา '\n",
      "                         'ที ่ 2/2566 เมื ่อวันที่   22 พฤษภาคม พ.ศ. 2566 '\n",
      "                         'ได้ครบก าหนดการปฏิบัติหน้าที่เม่ือวันที่ 31 กรกฎาคม '\n",
      "                         '2567 นั้น    อาศัยอ านาจตามความในมาตรา 23(10) '\n",
      "                         'แห่งพระราชบัญญัติกองทุนเพื่อความเสมอภาคทาง การศึกษา '\n",
      "                         'พ.ศ. 2561 คณะกรรมการบริหารกองทุนเพื'},\n",
      "    'location': { 's3Location': { 'uri': 's3://bedrock-kb-us-west-2-615631871157/Final_เอกสารประกอบวาระอนุกรรมการ '\n",
      "                                         'วสศ. ครั้งที่ 3_2567.pdf'},\n",
      "                  'type': 'S3'},\n",
      "    'metadata': { 'x-amz-bedrock-kb-chunk-id': '1%3A0%3AWLG_tpEBERi-GGUx2lti',\n",
      "                  'x-amz-bedrock-kb-data-source-id': 'OGRCYT4JHB',\n",
      "                  'x-amz-bedrock-kb-source-uri': 's3://bedrock-kb-us-west-2-615631871157/Final_เอกสารประกอบวาระอนุกรรมการ '\n",
      "                                                 'วสศ. ครั้งที่ 3_2567.pdf'},\n",
      "    'score': 0.5488174},\n",
      "  { 'content': { 'text': 'รองเลขาธิการ  o นางสาวอมรรัตน\\uf70e '\n",
      "                         'เงาวะบุญพัฒน\\uf70e    '\n",
      "                         'ฝ\\uf705ายกำกับติดตามประเมินผล    ๔.๒ '\n",
      "                         'วิธีการจัดการความเส่ียง o นายพรรคพงศ\\uf70e '\n",
      "                         'วุฒิวงศ\\uf70e   '\n",
      "                         'ฝ\\uf705ายบริหารและพัฒนาทรัพยากรบุคคล      ๔.๓ '\n",
      "                         '(ร\\uf70aาง) ประกาศเกษียณก\\uf70aอนอายุราชการ o '\n",
      "                         'นางสาวณัฐณภัค ลุผล  ผู\\uf70bอำนวยการฝ\\uf705าย '\n",
      "                         'ฝ\\uf705ายบริหารและพัฒนา ทรัพยากรบุคคล      ๔.๔ '\n",
      "                         'ทบทวนวรรณกรรมท่ีเกี่ยวข\\uf70bองกับระบบ Cyber  '\n",
      "                         'Security การเตรียมรับมือภัยคุกคาม และเทคโนโลยีท่ี '\n",
      "                         'เกี่ยวข\\uf70bอง    o นายประเทือง เผ\\uf70aาดิษฐ  '\n",
      "                         'ผู\\uf70bช\\uf70aวยเลขาธิการ สปสช.'},\n",
      "    'location': { 's3Location': { 'uri': 's3://bedrock-kb-us-west-2-615631871157/0_วาระการประชุม '\n",
      "                                         'PAM 2_66.pdf'},\n",
      "                  'type': 'S3'},\n",
      "    'metadata': { 'x-amz-bedrock-kb-chunk-id': '1%3A0%3AblO_tpEB4MOf1e-P1ZJc',\n",
      "                  'x-amz-bedrock-kb-data-source-id': 'OGRCYT4JHB',\n",
      "                  'x-amz-bedrock-kb-source-uri': 's3://bedrock-kb-us-west-2-615631871157/0_วาระการประชุม '\n",
      "                                                 'PAM 2_66.pdf'},\n",
      "    'score': 0.5464704}]\n"
     ]
    }
   ],
   "source": [
    "query = \"วาระประชุม PAM ล่าสุดมีอะไรบ้าง?\"\n",
    "response = retrieve(query, kb_id, 5)\n",
    "retrievalResults = response['retrievalResults']\n",
    "pp.pprint(retrievalResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the text chunks from the retrieveAPI response\n",
    "\n",
    "In the cell below, we will fetch the context from the retrieval results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch context from the response\n",
    "def get_contexts(retrievalResults):\n",
    "    contexts = []\n",
    "    for retrievedResult in retrievalResults: \n",
    "        contexts.append(retrievedResult['content']['text'])\n",
    "    return contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 'ระเบียบวาระการประชุมคณะกรรมการบรหิาร สปสช. ครั้งท่ี ๙/๒๕๖๖ วันท่ี ๒๗ '\n",
      "  'มิถุนายน ๒๕๖๖                                   ๑/๒             '\n",
      "  'ระเบียบวาระประชุมผู\\uf70bบริหาร สปสช. (Policy Advocacy Meeting: PAM) '\n",
      "  'คร้ังที่ ๒/๒๕๖๖  วันจันทร\\uf70eที่ ๑๐ กรกฎาคม ๒๕๖๖ เวลา ๑๓.๐๐ – ๑๖.๐๐ น.    '\n",
      "  'ณ ห\\uf70bองประชุม ๒๐๒ ชั้น ๒ สำนักงานหลักประกันสขุภาพแห\\uf70aงชาติ '\n",
      "  'และผ\\uf70aานสื่ออิเล็กทรอนิกส\\uf70e      o ประธานที่ประชุม : นพ. จเด็จ '\n",
      "  'ธรรมธัชอารี  เลขาธิการ สปสช.',\n",
      "  'ขอความร\\uf70aวมมือผู\\uf70bนำเสนอ นำเสนอแบบกระชบั ภายใน 5 นาที '\n",
      "  'ประกอบด\\uf70bวย ที่มา สรุปข\\uf70bอมูลสำคัญประกอบข\\uf70bอเสนอ  และ '\n",
      "  'ข\\uf70bอเสนอเพื่อพิจารณา/เพื่อทราบ และสำรองเวลา '\n",
      "  'สำหรับการอภิปรายและแลกเปลีย่นความเห็น  ๒. '\n",
      "  'ระเบียบวาระและเอกสารประกอบการประชุม วางไว\\uf70bที ่ 1. T:\\\\PAU meeting\\\\04 '\n",
      "  'ประชมุคณะกรรมการบริหาร\\\\เอกสารประกอบการประชุม\\\\2566\\\\กก.บ 9_2566  2. '\n",
      "  'https://drive.google.com/drive/folders/1Atv6E_J6v4_Z3K63p6mDYTMFk2sMmMV_?usp=drive_link',\n",
      "  'o นายทรงกรด เกษกาญจนานุช  '\n",
      "  'ฝ\\uf705ายสนับสนุนนโยบายด\\uf70bานเทคโนโลยสีารสนเทศ    o นายปริญัติ '\n",
      "  'ลิมป\\uf701ทีปราการ  ฝ\\uf705ายนวัตกรรมข\\uf70bอมูลอัจฉริยะ      '\n",
      "  'ระเบียบวาระที่ ๕ เร่ืองเพ่ือทราบ          '\n",
      "  'ระเบียบวาระการประชุมคณะกรรมการบรหิาร สปสช.',\n",
      "  'ประธาน/เลขานุการ แจ้งให้ที่ประชุมทราบ 1 เรื่อง ดังนี้  '\n",
      "  'การแต่งตั้งคณะอนุกรรมการก ากับทิศทางสถาบันวิจัยเพื่อความเสมอภาคทางการศึกษา  '\n",
      "  'ตามที่คณะอนุกรรมการก ากับทิศทางสถาบันวิจัยเพื่อความเสมอภาคทางการศึกษา '\n",
      "  'ซึ่งได้รับการ   แต่งตั ้งตามค าสั ่งคณะกรรมการบริหารกองทุนเพื '\n",
      "  '่อความเสมอภาคทางการศึกษา ที ่ 2/2566 เมื ่อวันที่   22 พฤษภาคม พ.ศ. 2566 '\n",
      "  'ได้ครบก าหนดการปฏิบัติหน้าที่เม่ือวันที่ 31 กรกฎาคม 2567 นั้น    อาศัยอ '\n",
      "  'านาจตามความในมาตรา 23(10) แห่งพระราชบัญญัติกองทุนเพื่อความเสมอภาคทาง '\n",
      "  'การศึกษา พ.ศ. 2561 คณะกรรมการบริหารกองทุนเพื',\n",
      "  'รองเลขาธิการ  o นางสาวอมรรัตน\\uf70e เงาวะบุญพัฒน\\uf70e    '\n",
      "  'ฝ\\uf705ายกำกับติดตามประเมินผล    ๔.๒ วิธีการจัดการความเส่ียง o '\n",
      "  'นายพรรคพงศ\\uf70e วุฒิวงศ\\uf70e   ฝ\\uf705ายบริหารและพัฒนาทรัพยากรบุคคล      '\n",
      "  '๔.๓ (ร\\uf70aาง) ประกาศเกษียณก\\uf70aอนอายุราชการ o นางสาวณัฐณภัค ลุผล  '\n",
      "  'ผู\\uf70bอำนวยการฝ\\uf705าย ฝ\\uf705ายบริหารและพัฒนา ทรัพยากรบุคคล      ๔.๔ '\n",
      "  'ทบทวนวรรณกรรมท่ีเกี่ยวข\\uf70bองกับระบบ Cyber  Security '\n",
      "  'การเตรียมรับมือภัยคุกคาม และเทคโนโลยีท่ี เกี่ยวข\\uf70bอง    o นายประเทือง '\n",
      "  'เผ\\uf70aาดิษฐ  ผู\\uf70bช\\uf70aวยเลขาธิการ สปสช.']\n"
     ]
    }
   ],
   "source": [
    "contexts = get_contexts(retrievalResults)\n",
    "pp.pprint(contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt specific to the model to personalize responses \n",
    "\n",
    "Here, we will use the specific prompt below for the model to act as a financial advisor AI system that will provide answers to questions by using fact based and statistical information when possible. We will provide the `Retrieve API` responses from above as a part of the `{contexts}` in the prompt for the model to refer to, along with the user `query`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Human: You are a secretariat of PAM Meeeing, and provides answers to questions by using fact based and statistical information when possible. \n",
    "Use the following pieces of information to provide a concise answer to the question enclosed in <question> tags. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "<context>\n",
    "{contexts}\n",
    "</context>\n",
    "\n",
    "<question>\n",
    "{query}\n",
    "</question>\n",
    "\n",
    "The response should be specific and use statistics or numbers when possible.\n",
    "\n",
    "Assistant:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke foundation model from Amazon Bedrock\n",
    "In this example, we will use `anthropic.claude-3-sonnet-20240229-v1:0` foundation model from Amazon Bedrock. \n",
    "- It offers maximum utility at a lower price than competitors, and is engineered to be the dependable, high-endurance workhorse for scaled AI deployments. Claude 3 Sonnet can process images and return text outputs, and features a 200K context window.\n",
    "- Model attributes\n",
    "    - Image to text & code, multilingual conversation, complex reasoning & analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# payload with model paramters\n",
    "messages=[{ \"role\":'user', \"content\":[{'type':'text','text': prompt.format(contexts, query)}]}]\n",
    "sonnet_payload = json.dumps({\n",
    "    \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "    \"max_tokens\": 512,\n",
    "    \"messages\": messages,\n",
    "    \"temperature\": 0.5,\n",
    "    \"top_p\": 1\n",
    "        }  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('จากข้อมูลที่ให้มา พบว่าไม่มีรายละเอียดของวาระการประชุม PAM ครั้งล่าสุด '\n",
      " 'แต่มีการระบุถึงวาระการประชุมของคณะกรรมการบริหาร สปสช. ครั้งที่ 9/2566 '\n",
      " 'เท่านั้น ดังนั้นจึงไม่สามารถตอบได้ว่าวาระการประชุม PAM ล่าสุดมีอะไรบ้าง')\n"
     ]
    }
   ],
   "source": [
    "modelId = 'anthropic.claude-3-sonnet-20240229-v1:0' # change this to use a different version from the model provider\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "response = bedrock_client.invoke_model(body=sonnet_payload, modelId=modelId, accept=accept, contentType=contentType)\n",
    "response_body = json.loads(response.get('body').read())\n",
    "response_text = response_body.get('content')[0]['text']\n",
    "\n",
    "pp.pprint(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - LangChain integration\n",
    "In this notebook, we will dive deep into building Q&A application using Retrieve API provided by Knowledge Bases for Amazon Bedrock and LangChain. We will query the knowledge base to get the desired number of document chunks based on similarity search, integrate it with LangChain retriever and use `Anthropic Claude 3 Sonnet` model for answering questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock\n",
    "from langchain.retrievers.bedrock import AmazonKnowledgeBasesRetriever\n",
    "\n",
    "llm = ChatBedrock(model_id=modelId, \n",
    "                  client=bedrock_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `AmazonKnowledgeBasesRetriever` object from LangChain which will call the `Retreive API` provided by Knowledge Bases for Amazon Bedrock which converts user queries into embeddings, searches the knowledge base, and returns the relevant results, giving you more control to build custom workﬂows on top of the semantic search results. The output of the `Retrieve API` includes the the `retrieved text chunks`, the `location type` and `URI` of the source data, as well as the relevance `scores` of the retrievals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3669/4125802233.py:13: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use invoke instead.\n",
      "  docs = retriever.get_relevant_documents(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Document(metadata={'location': {'s3Location': {'uri': 's3://bedrock-kb-us-west-2-615631871157/AMZN-2022-Shareholder-Letter.pdf'}, 'type': 'S3'}, 'score': 0.67195415}, page_content='Amazon has been using machine learning extensively for 25 years, employing it in everything from personalized ecommerce recommendations, to fulfillment center pick paths, to drones for Prime Air, to Alexa, to the many machine learning services AWS offers (where AWS has the broadest machine learning functionality and customer base of any cloud provider). More recently, a newer form of machine learning, called Generative AI, has burst onto the scene and promises to significantly accelerate machine learning adoption. Generative AI is based on very Large Language Models (trained on up to hundreds of billions of parameters, and growing), across expansive datasets, and has radically general and broad recall and learning capabilities. We have been working on our own LLMs for a while now, believe it will transform and improve virtually every customer experience, and will continue to invest substantially in these models across all of our consumer, seller, brand, and creator experiences. Additionally, as we’ve done for years in AWS, we’re democratizing this technology so companies of all sizes can leverage Generative AI. AWS is offering the most price-performant machine learning chips in Trainium and Inferentia so small and large companies can afford to train and run their LLMs in production. We enable companies to choose from various LLMs and build applications with all of the AWS security, privacy and other features that customers are accustomed to using. And, we’re delivering applications like AWS’s CodeWhisperer, which revolutionizes        developer productivity by generating code suggestions in real time. I could write an entire letter on LLMs and Generative AI as I think they will be that transformative, but I’ll leave that for a future letter. Let’s just say that LLMs and Generative AI are going to be a big deal for customers, our shareholders, and Amazon.   So, in closing, I’m optimistic that we’ll emerge from this challenging macroeconomic time in a stronger position than when we entered it. There are several reasons for it and I’ve mentioned many of them above. But, there are two relatively simple statistics that underline our immense future opportunity. While we have a consumer business that’s $434B in 2022, the vast majority of total market segment share in global retail still resides in physical stores (roughly 80%). And, it’s a similar story for Global IT spending, where we have AWS revenue of $80B in 2022, with about 90% of Global IT spending still on-premises and yet to migrate to the cloud.'),\n",
      "  Document(metadata={'location': {'s3Location': {'uri': 's3://bedrock-kb-us-west-2-615631871157/AMZN-2022-Shareholder-Letter.pdf'}, 'type': 'S3'}, 'score': 0.54837483}, page_content='Our Inferentia2 chip, which just launched, offers up to four times higher throughput and ten times lower latency than our first Inferentia processor. With the enormous upcoming growth in machine learning, customers will be able to get a lot more done with AWS’s training and inference chips at a significantly lower cost. We’re not close to being done innovating here, and this long-term investment should prove fruitful for both customers and AWS. AWS is still in the early stages of its evolution, and has a chance for unusual growth in the next decade.   Similarly high potential, Amazon’s Advertising business is uniquely effective for brands, which is part of why it continues to grow at a brisk clip. Akin to physical retailers’ advertising businesses selling shelf space, end- caps, and placement in their circulars, our sponsored products and brands offerings have been an integral part        of the Amazon shopping experience for more than a decade. However, unlike physical retailers, Amazon can tailor these sponsored products to be relevant to what customers are searching for given what we know about shopping behaviors and our very deep investment in machine learning algorithms. This leads to advertising that’s more useful for customers; and as a result, performs better for brands. This is part of why our Advertising revenue has continued to grow rapidly (23% YoY in Q4 2022, 25% YoY overall for 2022 on a $31B revenue base), even as most large advertising-focused businesses’ growth have slowed over the last several quarters.   We strive to be the best place for advertisers to build their brands. We have near and long-term opportunities that will help us achieve that mission. We’re continuing to make large investments in machine learning to keep honing our advertising selection algorithms. For the past couple of years, we’ve invested in building comprehensive, flexible, and durable planning and measurement solutions, giving marketers greater insight into advertising effectiveness. An example is Amazon Marketing Cloud (“AMC”). AMC is a “clean room” (i.e. secure digital environment) in which advertisers can run custom audience and campaign analytics across a range of first and third-party inputs, in a privacy-safe manner, to generate advertising and business insights to inform their broader marketing and sales strategies. The Advertising and AWS teams have collaborated to enable companies to store their data in AWS, operate securely in AMC with Amazon and other third-party data sources, perform analytics in AWS, and have the option to activate advertising on Amazon or third-party publishers through the Amazon Demand-Side Platform.'),\n",
      "  Document(metadata={'location': {'s3Location': {'uri': 's3://bedrock-kb-us-west-2-615631871157/AMZN-2022-Shareholder-Letter.pdf'}, 'type': 'S3'}, 'score': 0.5332557}, page_content='Imagine what they’ll be able to do with reliable connectivity, from people taking online education courses, using financial services, starting their own businesses, doing their shopping, enjoying entertainment, to businesses and governments improving their coverage, efficiency, and operations. Kuiper will deliver not only accessibility, but affordability. Our teams have developed low-cost antennas (i.e. customer terminals) that will lower the barriers to access. We recently unveiled the new terminals that will communicate with the satellites passing overhead, and we expect to be able to produce our standard residential version for less than $400 each. They’re small: 11 inches square, 1 inch thick, and weigh less than 5 pounds without their mounting bracket, but they deliver speeds up to 400 megabits per second. And they’re powered by Amazon-designed baseband chips. We’re preparing to launch two prototype satellites to test the entire end-to-end communications network this year, and plan to be in beta with commercial customers in 2024. The customer reaction to what we’ve shared thus far about Kuiper has been very positive, and we believe Kuiper represents a very large potential opportunity for Amazon. It also shares several similarities to AWS in that it’s capital intensive at the start, but has a large prospective consumer, enterprise, and government customer base, significant revenue and operating profit potential, and relatively few companies with the technical and inventive aptitude, as well as the investment hypothesis to go after it.   One final investment area that I’ll mention, that’s core to setting Amazon up to invent in every area of our business for many decades to come, and where we’re investing heavily is Large Language Models (“LLMs”) and Generative AI. Machine learning has been a technology with high promise for several decades, but it’s only been the last five to ten years that it’s started to be used more pervasively by companies. This shift was driven by several factors, including access to higher volumes of compute capacity at lower prices than was ever available. Amazon has been using machine learning extensively for 25 years, employing it in everything from personalized ecommerce recommendations, to fulfillment center pick paths, to drones for Prime Air, to Alexa, to the many machine learning services AWS offers (where AWS has the broadest machine learning functionality and customer base of any cloud provider). More recently, a newer form of machine learning, called Generative AI, has burst onto the scene and promises to significantly accelerate machine learning adoption.'),\n",
      "  Document(metadata={'location': {'s3Location': {'uri': 's3://bedrock-kb-us-west-2-615631871157/AMZN-2022-Shareholder-Letter.pdf'}, 'type': 'S3'}, 'score': 0.5315453}, page_content='We believe that we’ve only scratched the surface of what’s possible to date, and plan to keep building the features our business customers tell us they need and want.   While many brands and merchants successfully sell their products on Amazon’s marketplace, there are also a large number of brands and sellers who have launched their own direct-to-consumer websites. One of the challenges for these merchants is driving conversion from views to purchases. We invented Buy with Prime to help with this challenge. Buy with Prime allows third-party brands and sellers to offer their products on their own websites to our large Amazon Prime membership, and offer those customers fast, free Prime shipping and seamless checkout with their Amazon account. Buy with Prime provides merchants several additional benefits, including Amazon handling the product storage, picking, packing, delivery, payment, and any returns, all through Amazon Pay and Fulfillment by Amazon. Buy with Prime has recently been made available to all US merchants; and so far, Buy with Prime has increased shopper conversion on third-party shopping sites by 25% on average. Merchants are excited about converting more sales and fulfilling these shipments more easily, Prime members love that they can use their Prime benefits on more destinations, and Buy with Prime allows us to improve the shopping experience across more of the web.   Expanding internationally, pursuing large retail market segments that are still nascent for Amazon, and using our unique assets to help merchants sell more effectively on their own websites are somewhat natural extensions for us. There are also a few investments we’re making that are further from our core businesses, but where we see unique opportunity. In 2003, AWS would have been a classic example. In 2023, Amazon Healthcare and Kuiper are potential analogues.   Our initial efforts in Healthcare began with pharmacy, which felt less like a major departure from ecommerce. For years, Amazon customers had asked us when we’d offer them an online pharmacy as their frustrations mounted with current providers. Launched in 2020, Amazon Pharmacy is a full-service, online pharmacy that offers transparent pricing, easy refills, and savings for Prime members. The business is growing quickly, and continues to innovate. An example is Amazon Pharmacy’s recent launch of RxPass, which for a $5 per        month flat fee, enables Prime members to get as many of the eligible prescription medications as they need for dozens of common conditions, like high blood pressure, acid reflux, and anxiety.')]\n"
     ]
    }
   ],
   "source": [
    "query = \"What is Amazon doing in the field of Generative AI?\"\n",
    "retriever = AmazonKnowledgeBasesRetriever(\n",
    "        knowledge_base_id=kb_id,\n",
    "        retrieval_config={\"vectorSearchConfiguration\": \n",
    "                          {\"numberOfResults\": 4,\n",
    "                           'overrideSearchType': \"SEMANTIC\", # optional\n",
    "                           }\n",
    "                          },\n",
    "        # endpoint_url=endpoint_url,\n",
    "        # region_name=region,\n",
    "        # credentials_profile_name=\"<profile_name>\",\n",
    "    )\n",
    "docs = retriever.get_relevant_documents(\n",
    "        query=query\n",
    "    )\n",
    "pp.pprint(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt specific to the model to personalize responses\n",
    "\n",
    "Here, we will use two helper functions to build the chain to invoke the model:\n",
    "- `create_stuff_documents_chain` specifies how retrieved context is fed into a prompt and LLM. In this case, we will \"stuff\" the contents into the prompt -- i.e., we will include all retrieved context without any summarization or other processing. It largely implements our above rag_chain, with input keys context and input-- it generates an answer using retrieved context and query.\n",
    "- `create_retrieval_chain`  adds the retrieval step and propagates the retrieved context through the chain, providing it alongside the final answer. It has input key input, and includes input, context, and answer in its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('According to the context provided, Amazon has been investing significantly '\n",
      " 'in Generative AI and Large Language Models (LLMs). Some key points:\\n'\n",
      " '\\n'\n",
      " '1. Amazon believes Generative AI and LLMs will transform and improve '\n",
      " 'virtually every customer experience across its consumer, seller, brand, and '\n",
      " 'creator offerings. \\n'\n",
      " '\\n'\n",
      " '2. Amazon has been working on developing its own LLMs for a while and plans '\n",
      " 'to continue investing substantially in these models.\\n'\n",
      " '\\n'\n",
      " '3. Amazon is democratizing this technology through AWS, offering '\n",
      " 'high-performance and cost-effective machine learning chips like Trainium and '\n",
      " 'Inferentia to allow companies of all sizes to train and run LLMs in '\n",
      " 'production.\\n'\n",
      " '\\n'\n",
      " '4. AWS is enabling companies to choose from various LLMs and build '\n",
      " \"applications leveraging AWS's security, privacy, and other features.\\n\"\n",
      " '\\n'\n",
      " '5. AWS has already delivered applications like CodeWhisperer that uses '\n",
      " 'Generative AI to provide real-time code suggestions, boosting developer '\n",
      " 'productivity.\\n'\n",
      " '\\n'\n",
      " 'In summary, Amazon views Generative AI and LLMs as highly transformative '\n",
      " 'technologies and is investing heavily to develop its own LLMs, offer related '\n",
      " 'services and infrastructure through AWS, and integrate this AI across its '\n",
      " 'products and customer experiences.')\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": query})\n",
    "pp.pprint(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "You can use Retrieve API for customizing your RAG based application, using either `InvokeModel` API from Bedrock, or you can integrate with LangChain using `AmazonKnowledgeBaseRetriever`.\n",
    "Retrieve API provides you with the flexibility of using any foundation model provided by Amazon Bedrock, and choosing the right search type, either HYBRID or SEMANTIC, based on your use case. \n",
    "Here is the [blog](#https://aws.amazon.com/blogs/machine-learning/knowledge-bases-for-amazon-bedrock-now-supports-hybrid-search/) for Hybrid Search feature, for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
